---
title: "How to Use the rstanarm Package"
author: "Jonah Gabry and Ben Goodrich"
date: "08/30/2015"
output: 
  html_document: 
    fig_caption: yes
    toc: yes
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{How to Use the rstanarm Package}
-->

# Introduction

This vignette provides an _overview_ of how to use the functions in the
__rstanarm__ package that focuses on commonalities. Each specific estimation
function in the __rstanarm__ package has a separate vignette that goes into
the particularities of that function.

The goal of the __rstanarm__ package is to make Bayesian estimation
_routine_ for the most common regression models that applied researchers use.
This will enable researchers to avoid the counter-intuitiveness of the
frequentist approach to probability and statistics with only minimal changes to
their existing R scripts.

The four steps of a Bayesian analysis are

1. Specify a joint distribution for the outcome(s) and all the unknowns, which
  typically takes the form of a marginal prior distribution for the unknowns
  multiplied by a likelihood for the outcome(s) conditional on the unknowns.
  This joint distribution is proportional to a posterior distribution of the
  unknowns conditional on the observed data
2. Draw from posterior distribution using Markov Chain Monte Carlo (MCMC).
3. Evaluate how well the model fits the data and possibly revise the model.
4. Draw from the posterior predictive distribution of the outcome(s) given
  interesting values of the predictors in order to visualize how a manipulation
  of a predictor affects (a function of) the outcome(s).
  
Step 1 is necessarily model-specific and is covered in more detail in the other
vignettes that cover specific forms of the marginal prior distribution and
likelihood of the outcome. It is somewhat more involved than the corresponding
first step of a frequentist analysis, which only requires that the likelihood
of the outcome be specified. However, the default priors in the __rstanarm__
package should work well in many cases. Steps 2, 3, and 4 are the focus of this 
vignette because they are largely not specific to how the joint distribution in 
Step 1 is specified.

The key concept in steps 3 and 4 is the posterior predictive distribution, 
which is the distribution of the outcome implied by the model after having 
used the observed data to update our beliefs about the unknown parameters.
Frequentists, by definition, have no posterior predictive distribution and 
frequentist predictions are subtly different from what applied researchers seek.
Maximum likelihood estimates do _not_ condition on the observed outcome
data and the uncertainty pertains to the variation in the sampling distribution
of the estimator, i.e. the distribution of estimates that would occur if we
could repeat the process of drawing a random sample from a well-defined 
population and apply the estimator to each sample. It is possible to construct
a distribution of predictions under the frequentist paradigm but it evokes the
hypothetical of repeating the process of drawing a random sample, applying the
estimator each time, and generating point predictions of the outcome. In
contrast, the posterior predictive distribution conditions on the observed 
outcome data in hand to update beliefs about the unknowns and the
variation in the resulting distribution of predictions reflects the remaining
uncertainty in our beliefs about the unknowns.

# Step 1: Specify a posterior distribution

For the sake of discussion, we need some posterior distribution to draw from. 
We will use an example from the __HSAUR__ package by Brian S. Everitt and 
Torsten Hothorn, which is used in their 2006 book 
_A Handbook of Statistical Analyses Using R (1st Edition)_ (Chapman & Hall /
CRC). This book is frequentist in nature and we will show how to obtain the 
corresponding Bayesian results.

The model in section 6.3.2 pertains to whether a survey respondent agrees or
disagrees with a conservative statement about the role of women in society, 
which is modeled as a function of the sex and education of the respondents. 
The posterior distribution --- with independent priors --- can be written as
$$f\left(\alpha,\beta_1,\beta_2|\mathbf{y},\mathbf{X}\right) \propto
  f\left(\alpha\right) f\left(\beta_1\right) f\left(\beta_2\right) \times
  \prod_{i=1}^J {
  g^{-1}\left(\eta_i\right)^{y_i} 
  \left(1 - g^{-1}\left(\eta_i\right)\right)^{n_i-y_i}},$$
where $\eta_i = \alpha + \beta_1 \mbox{education}_i + \beta_2 \mbox{Female}_i$ 
is the linear predictor and a function of an intercept $\left(\alpha\right)$, 
a coefficient on the years of education $\left(\beta_1\right)$, and an 
intercept-shift $\left(\beta_2\right)$ for the case where the respondent is 
female. These data are organized such that $y_i$ is the number of people who 
agree with the statement that have the same level of education and the same sex
and $n_i - y_i$ is the number of such people who disagree with the statement. 
The inverse link function, $p = g^{-1}\left(\eta_i \right)$, for a binomial
likelihood can be one of several Cumulative Distribution Functions (CDFs) but 
in this case is the standard logistic CDF, 
$g^{-1}\left(\eta_i \right)=\frac{1}{1 + e^{-\eta_i}}$.

Suppose we believe --- prior to seeing the data --- that $\alpha$, 
$\beta_1$, and $\beta_2$ are probably close to zero, are as likely to be 
positive as they are to be negative, but have a small chance of being
quite far from zero. These beliefs can be represented by Student t 
distributions with a few degrees of freedom in order to produce moderately
heavy tails. In particular, we will specify seven degrees of freedom.
Note that these purported beliefs may well be more skeptical than your 
actual beliefs, which are probably that women and people with more
education have less conservative societal views.

# Step 2: Draw from the posterior distribution

The likelihood for the sample is just the product over the $J$ groups of
$$g^{-1}\left(\eta_i \right)^{y_i} 
  \left(1 - g^{-1}\left(\eta_i \right)\right)^{n_i-y_i},$$
which can be maximized over $\alpha$, $\beta_1$, and $\beta_2$ to obtain 
frequentist estimates by calling
```{r MLE}
data("womensrole", package = "HSAUR")
womensrole$total <- womensrole$agree + womensrole$disagree
womensrole_glm_1 <- glm(cbind(agree, disagree) ~ education + sex,
                        data = womensrole, family = binomial(link = "logit"))
round(coef(summary(womensrole_glm_1)), 3)
```
The p-value for the null hypothesis that $\beta_1 = 0$ is very small, while
the p-value for the null hypothesis that $\beta_2 = 0$ is very large. However,
frequentist p-values are awkward because they do not pertain to the probability
that a scientific hypothesis is true but rather to the probability of observing
a z-statistic that is so large (in magnitude) if the null hypothesis were true.
The desire to make probabalistic statements about a scientific hypothesis is
one reason why many people are drawn to the Bayesian approach. 

A model with the same likelihood but Student t priors with seven degrees of 
freedom can be specified using the __rstanarm__ package in a similar way by
prepending `stan_` to the `glm` call and specifying priors (and optionally
the number of cores on your computer to utilize):
```{r MCMC}
suppressPackageStartupMessages(require(rstanarm))
womensrole_bglm_1 <- stan_glm(cbind(agree, disagree) ~ education + sex,
                              data = womensrole, seed = 12345,
                              family = binomial(link = "logit"), 
                              cores = 2, prior = student_t(df = 7), 
                              prior.for.intercept = student_t(df = 7))
womensrole_bglm_1
```
As can be seen, the "Bayesian point estimates" --- which are represented by
the posterior medians --- are very similar to the maximum likelihood estimates.
Frequentists would ask whether the point estimate is greater in magnitude than
double the estimated standard deviation of the sampling distribution. But here
we simply have estimates of the standard deviation of the marginal posterior
distributions, which are based on a scaling of the Median Absolute Deviation
(MAD) from the posterior medians. In addition, we can obtain a credible 
interval for $\beta_1$ by calling
```{r CI}
round(confint(womensrole_bglm_1, parm = "education"), 2)
```
which --- unlike frequentist confidence intervals, despite using the `confint`
method --- indicates that we believe after seeing the data that there is a 
$0.95$ probability that $\beta_2$ is between $-0.30$ and $-0.24$. 
Alternatively, we could say that there is essentially zero probability that
$\beta_2 > 0$, although frequentists cannot make such a claim coherently.

Many of the postestimation methods --- such as `confint` --- that are available
for a model that is estimated by `glm` are also available for a model that is
estimated by `stan_glm`. For example,
```{r methods}
cbind(Median = coef(womensrole_bglm_1), MAD_SD = se(womensrole_bglm_1))
summary(residuals(womensrole_bglm_1)) # not deviance residuals
cov2cor(vcov(womensrole_bglm_1))
```


# Step 3: Criticize the model

The `launch_shinystan` function in the __shinystan__ package provides almost
all the tools you need to visualize the posterior distribution and diagnose
any problems with the Markov chains. In this case, the results are fine and
to verify that, you can call
```{r shinystan,eval=FALSE}
launch_shinystan(womensrole_bglm_1)
```
which will open a web browser that drives the visualizations. 

For the rest of this subsection, we focus on what users can do programatically
to evaluate whether a model is adequate. A minimal requirement for a Bayesian 
estimates is that the model should fit the data that the estimates conditioned
on. The key function here is `posterior_predict`, which can be passed a new 
`data.frame` to predict out-of-sample, but in this case is omitted to obtain 
in-sample posterior predictions:
```{r PPD}
y_rep <- posterior_predict(womensrole_bglm_1)
dim(y_rep)
```
The resulting matrix has rows equal to the number of posterior simulations,
which in this case is $4000$ and columns equal to the number of observations
in the original dataset, which is $42$ combinations of education and sex.
Each element of this matrix is a predicted number of respondents with that
value of education and sex who agreed with the survey question and thus 
should be reasonably close to the observed proportion of agreements in the 
data. We can create a plot to check this:
```{r criticism, fig.width=10, fig.cap="Posterior predictive boxplots vs. observed datapoints"}
par(mfrow = 1:2, mar = c(5,3.7,1,0) + 0.1, las = 3)
boxplot(sweep(y_rep[,womensrole$sex == "Male"], 2, STATS = 
               womensrole$total[womensrole$sex == "Male"], FUN = "/"), 
        axes = FALSE, main = "Male", pch = NA,
        xlab = "Years of Education", ylab = "Proportion of Agrees")
with(womensrole, axis(1, at = education[sex == "Male"] + 1, 
                      labels = 0:20))
axis(2, las = 1)
with(womensrole[womensrole$sex == "Male",], 
     points(education + 1,  agree / (agree + disagree), 
            pch = 16, col = "red"))
boxplot(sweep(y_rep[,womensrole$sex == "Female"], 2, STATS = 
          womensrole$total[womensrole$sex == "Female"], FUN = "/"), 
          axes = FALSE, main = "Female", pch = NA,
        xlab = "Years of Education", ylab = "")
with(womensrole, axis(1, at = education[sex == "Female"] + 1,
     labels = 0:20))
with(womensrole[womensrole$sex == "Female",], 
     points(education + 1,  agree / (agree + disagree), 
            pch = 16, col = "red"))
```
Here the boxplots provide the median, interquartile range, and hinges of the
posterior predictive distribution for a given sex and level of education, while
the red points represent the corresponding observed data. As can be seen, the
model predicts the observed data fairly well for six to sixteen years of 
education but predicts less well for very low or very high levels of education
where there are less data. 

Consequently, we might consider a model where education has a quadratic effect 
on agreement, which is easy to specify using R's formula-based syntax.
```{r}
womensrole_bglm_2 <- stan_glm(cbind(agree, disagree) ~ education
                              + I(education^2) + sex, data = womensrole,
                              seed = 12345, family = binomial(link = "logit"),
                              cores = 2, prior = student_t(df = 7), 
                              prior.for.intercept = student_t(df = 7))
womensrole_bglm_2
```
Frequentists would test the null hypothesis that the coefficient on the 
squared level of education is zero. Bayesians might ask whether such a model
is expected to produce better out-of-sample predictions than a model with
only the level of education. The latter question can be answered using
leave-one-out cross-validation or the approximation thereof provided by the
`loo` function in the __loo__ package, for which a method is provided by the
__rstanarm__ package.
```{r loo}
loo_bglm_1 <- loo(womensrole_bglm_1, cores = 2)
loo_bglm_2 <- loo(womensrole_bglm_2, cores = 2)
```
First, we verify that the posterior is not too sensitive to any particular
observation in the dataset.
```{r loo_plot}
par(mfrow = 1:2, mar = c(5,3.8,1,0) + 0.1, las = 3)
plot(loo_bglm_1, label_points = TRUE)
plot(loo_bglm_2, label_points = TRUE)
```

There are only one or two moderate outliers (whose statistics are greater
than $0.5$), which should not have too much of an effect on the resulting model
comparison:
```{r}
suppressPackageStartupMessages(require(loo))
compare(loo_bglm_1, loo_bglm_2)
```
In this case, there is little difference in the expected log pointwise
deviance between the two models, so we are essentially indifferent between
them after taking into account that the second model estimates an additional
parameter. [SAY MORE ABOUT WHY LOO IS BETTER]

# Step 4: Analyze manipulations of predictors

Frequentists attempt to interpret the estimates of the model, which is 
difficult except when the model is linear, has no inverse link function,
and contains no interaction terms. Bayesians can avoid this difficulty 
simply by inspecting the posterior predictive distribution at different
levels of the predictors. For example,
```{r}
y_rep <- posterior_predict(womensrole_bglm_2, newdata = 
                             data.frame(education = c(12,16),
                                        sex = factor("Female", levels = 
                                                     c("Male", "Female"))))
y_rep <- with(womensrole, sweep(y_rep, 2, FUN = "/", STATS = 
                total[sex == "Female" & education %in% c(12,16)]))
summary(apply(y_rep, 1, diff))
```
As can be seen, two women --- one with a high school degree and another
with a college degree --- are expected to have about the same probability
of agreeing with the survey question. This is largely due to the fact that
women with a high school education are already extremely unlikely to agree
with the survey question and thus increasing their education to a college
degree cannot have a large negative impact on this probability. Thus, to
the extent that education makes a difference to the outcome, it is mostly
that people with very little education have a considerable probability of
agreeing with the survey question.

# Conclusion

In this vignette, we have gone through the four steps of a Bayesian analysis.
The first step --- specifying the posterior distribution --- varies 
considerably from one analysis to the next because the likelihood function
employed differs depending on the nature of the outcome variable and our
prior beliefs about the parameters in the model varies not only from situation
to situation but from researcher to researcher. However, given a posterior
distribution and given that this posterior distribution can be drawn from
using the __rstanarm__ package, the remaining steps are conceptually similar
across analyses. The key is to draw from the posterior predictive distribution
of the outcome, which is the what the model predicts the outcome to be after
having updated our beliefs about the unknown parameters with the observed data.
Posterior predictive distributions can be used for model checking and for 
making inferences about how manipulations of the predictors would affect the
outcome.

If the posterior distribution that you specify in the first step cannot be
sampled from using the __rstanarm__ package, then it is often possible to 
create a hand-written program in the the Stan language so that the posterior
distribution can be drawn from using the __rstan__ package. See the 
documentation for the __rstan__ package or http://mc-stan.org for more
details about this more advanced useage of Stan. However, many relatively
simple models can be fit using the __rstanarm__ package without writing any
code in the Stan language, which is illustrated for each estimating function
in the __rstanarm__ package in the other vignettes.